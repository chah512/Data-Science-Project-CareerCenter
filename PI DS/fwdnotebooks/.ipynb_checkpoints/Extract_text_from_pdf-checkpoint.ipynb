{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5dc0681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (1.26.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f889a7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75013e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    " \n",
    "#create file object variable\n",
    "#opening method will be rb\n",
    "pdffileobj=open(r\"C:\\Users\\elyes\\Desktop\\espritAlumni\\candidate_000.pdf\",'rb')\n",
    " \n",
    "#create reader variable that will read the pdffileobj\n",
    "pdfreader=PyPDF2.PdfFileReader(pdffileobj)\n",
    " \n",
    "#This will store the number of pages of this pdf file\n",
    "x=pdfreader.numPages\n",
    "output1=''\n",
    "#create a variable that will select the selected number of pages\n",
    "for i in range(x):\n",
    "    page = pdfreader.getPage(i)\n",
    "    output1 += page.extractText()\n",
    "\n",
    "\n",
    "#(x+1) because python indentation starts with 0.\n",
    "#create text variable which will store all text datafrom pdf file\n",
    "#text=pageobj.extractText()\n",
    " \n",
    "#save the extracted data from pdf to a txt file\n",
    "#we will use file handling here\n",
    "#dont forget to put r before you put the file path\n",
    "#go to the file location copy the path by right clicking on the file\n",
    "#click properties and copy the location path and paste it here.\n",
    "#put \"\\\\your_txtfilename\"\n",
    "#file1=open(r\"C:\\Users\\elyes\\Desktop\\espritAlumni\\candidate_004.txt\",\"a\")\n",
    "#file1.writelines(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72530168",
   "metadata": {},
   "source": [
    "# First step: converting PDF to TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d195d2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 19:52:23,954 [MainThread  ] [WARNI]  Failed to see startup log message; retrying...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "candidate_000\n",
      "\n",
      "\n",
      "JACOB SMITH\n",
      "F R E S H E R\n",
      "\n",
      "SKILLS\n",
      "\n",
      "Python, SQL, MySQL, Tableau, Power\n",
      "Bi, Pandas , Numpy, Matplotlib, Excel ,\n",
      "Machine Learning, AWS(EMR,EC2,S3),\n",
      "Cloud, Hive(HQL), and Excel\n",
      "\n",
      "EDUCATION\n",
      "\n",
      "B. Tech, ECE VIT-AP University 2020\n",
      "\n",
      "OTHER ACTIVITIES\n",
      "\n",
      "Deep Learning Masters\n",
      "Machine Learning\n",
      "\n",
      "PROJECTS\n",
      "\n",
      "Music Genre Classification \n",
      "Face, eye, smile recognition\n",
      "\n",
      "PERSONAL PROFILE\n",
      "I am actively seeking opportunity as Data\n",
      "Analyst or Machine Learning Engineer.\n",
      "\n",
      "My goal is to discover new business\n",
      "strategies and create an impact through\n",
      "data driven analytical decisions and\n",
      "leading the business to success.\n",
      "\n",
      "WORK BACKGROUND\n",
      "\n",
      "Experts Hub\n",
      "Intern, May 2019\n",
      "\n",
      "I was part of a team that designed and developed a smart parking system\n",
      "based on Object Recognition. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!pip install tika\n",
    "from tika import parser # pip install tika\n",
    "\n",
    "#raw = parser.from_file(r\"C:\\Users\\elyes\\Desktop\\espritAlumni\\candidate_004.pdf\")\n",
    "raw1 = parser.from_file(r\"C:\\Users\\elyes\\Desktop\\espritAlumni\\candidate_000.pdf\")\n",
    "\n",
    "print(raw1['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7c37da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw1['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aeec1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0c890f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Author': 'Archan Ghosh',\n",
       " 'Content-Type': 'application/pdf',\n",
       " 'Creation-Date': '2021-07-01T15:29:53Z',\n",
       " 'Keywords': 'DAEiqA51-II,BACiUMUwBfE',\n",
       " 'Last-Modified': '2021-07-01T15:29:53Z',\n",
       " 'Last-Save-Date': '2021-07-01T15:29:53Z',\n",
       " 'X-Parsed-By': ['org.apache.tika.parser.DefaultParser',\n",
       "  'org.apache.tika.parser.pdf.PDFParser'],\n",
       " 'X-TIKA:content_handler': 'ToTextContentHandler',\n",
       " 'X-TIKA:embedded_depth': '0',\n",
       " 'X-TIKA:parse_time_millis': '797',\n",
       " 'access_permission:assemble_document': 'true',\n",
       " 'access_permission:can_modify': 'true',\n",
       " 'access_permission:can_print': 'true',\n",
       " 'access_permission:can_print_degraded': 'true',\n",
       " 'access_permission:extract_content': 'true',\n",
       " 'access_permission:extract_for_accessibility': 'true',\n",
       " 'access_permission:fill_in_form': 'true',\n",
       " 'access_permission:modify_annotations': 'true',\n",
       " 'created': '2021-07-01T15:29:53Z',\n",
       " 'creator': 'Archan Ghosh',\n",
       " 'date': '2021-07-01T15:29:53Z',\n",
       " 'dc:creator': 'Archan Ghosh',\n",
       " 'dc:format': 'application/pdf; version=1.4',\n",
       " 'dc:subject': 'DAEiqA51-II,BACiUMUwBfE',\n",
       " 'dc:title': 'candidate_000',\n",
       " 'dcterms:created': '2021-07-01T15:29:53Z',\n",
       " 'dcterms:modified': '2021-07-01T15:29:53Z',\n",
       " 'meta:author': 'Archan Ghosh',\n",
       " 'meta:creation-date': '2021-07-01T15:29:53Z',\n",
       " 'meta:keyword': 'DAEiqA51-II,BACiUMUwBfE',\n",
       " 'meta:save-date': '2021-07-01T15:29:53Z',\n",
       " 'modified': '2021-07-01T15:29:53Z',\n",
       " 'pdf:PDFVersion': '1.4',\n",
       " 'pdf:charsPerPage': '696',\n",
       " 'pdf:docinfo:created': '2021-07-01T15:29:53Z',\n",
       " 'pdf:docinfo:creator': 'Archan Ghosh',\n",
       " 'pdf:docinfo:creator_tool': 'Canva',\n",
       " 'pdf:docinfo:keywords': 'DAEiqA51-II,BACiUMUwBfE',\n",
       " 'pdf:docinfo:modified': '2021-07-01T15:29:53Z',\n",
       " 'pdf:docinfo:producer': 'Canva',\n",
       " 'pdf:docinfo:title': 'candidate_000',\n",
       " 'pdf:encrypted': 'false',\n",
       " 'pdf:hasMarkedContent': 'true',\n",
       " 'pdf:hasXFA': 'false',\n",
       " 'pdf:hasXMP': 'false',\n",
       " 'pdf:unmappedUnicodeCharsPerPage': '0',\n",
       " 'producer': 'Canva',\n",
       " 'resourceName': \"b'candidate_000.pdf'\",\n",
       " 'subject': 'DAEiqA51-II,BACiUMUwBfE',\n",
       " 'title': 'candidate_000',\n",
       " 'xmp:CreatorTool': 'Canva',\n",
       " 'xmpTPg:NPages': '1'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw1['metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a82e144",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Archan Ghosh'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw1['metadata']['Author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "343a3010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw1['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc40ab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines= raw1['content'].splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a00d4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'candidate_000',\n",
       " '',\n",
       " '',\n",
       " 'JACOB SMITH',\n",
       " 'F R E S H E R',\n",
       " '',\n",
       " 'SKILLS',\n",
       " '',\n",
       " 'Python, SQL, MySQL, Tableau, Power',\n",
       " 'Bi, Pandas , Numpy, Matplotlib, Excel ,',\n",
       " 'Machine Learning, AWS(EMR,EC2,S3),',\n",
       " 'Cloud, Hive(HQL), and Excel',\n",
       " '',\n",
       " 'EDUCATION',\n",
       " '',\n",
       " 'B. Tech, ECE VIT-AP University 2020',\n",
       " '',\n",
       " 'OTHER ACTIVITIES',\n",
       " '',\n",
       " 'Deep Learning Masters',\n",
       " 'Machine Learning',\n",
       " '',\n",
       " 'PROJECTS',\n",
       " '',\n",
       " 'Music Genre Classification ',\n",
       " 'Face, eye, smile recognition',\n",
       " '',\n",
       " 'PERSONAL PROFILE',\n",
       " 'I am actively seeking opportunity as Data',\n",
       " 'Analyst or Machine Learning Engineer.',\n",
       " '',\n",
       " 'My goal is to discover new business',\n",
       " 'strategies and create an impact through',\n",
       " 'data driven analytical decisions and',\n",
       " 'leading the business to success.',\n",
       " '',\n",
       " 'WORK BACKGROUND',\n",
       " '',\n",
       " 'Experts Hub',\n",
       " 'Intern, May 2019',\n",
       " '',\n",
       " 'I was part of a team that designed and developed a smart parking system',\n",
       " 'based on Object Recognition. ',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b108b3",
   "metadata": {},
   "source": [
    "# Step two : Identifying key words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "319edbbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tika import parser\n",
    "# import required module\n",
    "import os\n",
    "# assign directory\n",
    "directory = r\"C:\\Users\\elyes\\Desktop\\espritAlumni\\HireAMLE\\dataset\\trainResumes\"\n",
    "titles = []\n",
    "length = 0\n",
    "# iterate over files in\n",
    "# that directory\n",
    "for filename in os.listdir(directory):\n",
    "    length += 1\n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "        raw = parser.from_file(f)\n",
    "        lines= raw['content'].splitlines()\n",
    "        author = raw['metadata']['Author'].replace(\" \",\"\").upper()\n",
    "        for line in lines:\n",
    "           # line = line.replace(\" \",\"\")\n",
    "            if(line == author):\n",
    "                print(line)\n",
    "            if(line.isupper() and line.count(\" \")==2):\n",
    "                titles.append(line)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad284ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88b7f275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ARCHANGHOSH'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author = raw['metadata']['Author'].replace(\" \",\"\").upper()\n",
    "author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6a1a6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'candidate_149',\n",
       " '',\n",
       " '',\n",
       " 'MIRAD YASTEIN',\n",
       " 'A N A L Y S T  I N T E R N',\n",
       " '',\n",
       " 'SKILLS',\n",
       " '',\n",
       " 'Artificial Intelligence, Deep Learning,',\n",
       " 'Reinforcement Learning, Tensorflow',\n",
       " 'Keras, Scikit learn, Numpy, Pandas,',\n",
       " 'Matplotlib.',\n",
       " '',\n",
       " 'EDUCATION',\n",
       " '',\n",
       " 'B.Tech(IT) from IIIT D&M Kancheepuram, Chennai in 2019',\n",
       " '',\n",
       " 'PERSONAL PROFILE',\n",
       " 'Machine Learning Engineer seeking',\n",
       " 'assignments Deep Learning, Reinforcement',\n",
       " 'Learning, Tensorflow. Keras.',\n",
       " '',\n",
       " 'WORK BACKGROUND',\n",
       " '',\n",
       " 'Larsen & Toubro ',\n",
       " 'Analyst Intern, Dec 2019-Till Date ',\n",
       " '',\n",
       " 'Building OCR Models based on test report data',\n",
       " '',\n",
       " 'OTHER ACTIVITIES',\n",
       " '',\n",
       " 'KSST Scholar',\n",
       " '',\n",
       " 'PROJECTS',\n",
       " '',\n",
       " 'Wesbite Using React ',\n",
       " 'Made a Fully customizable website for',\n",
       " 'a company',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "101b6562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "unique_list = []\n",
    "unique_list1 = []\n",
    "\n",
    "def unique(list1):\n",
    " \n",
    "    # initialize a null list\n",
    "    \n",
    "     \n",
    "    # traverse for all elements\n",
    "    for x in list1:\n",
    "        # check if exists in unique_list or not\n",
    "        if x not in unique_list1:\n",
    "            unique_list1.append(x)\n",
    "    # print list\n",
    "   # for x in unique_list:\n",
    "    #    print(x)\n",
    "        \n",
    "        \n",
    "unique(titles)\n",
    "len(unique_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1469683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueee =[]\n",
    "def trimm():\n",
    "    for x in unique_list1:\n",
    "        uniqueee.append(x.replace(\" \", \"\"))\n",
    "        \n",
    "trimm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85ae109d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uniqueee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "019216c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4199340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_unique = []\n",
    "for x in uniqueee:\n",
    "        # check if exists in unique_list or not\n",
    "        if x not in new_unique:\n",
    "            new_unique.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86ee4aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "354783cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JUNIORNLPENGINEER',\n",
       " 'ACHIEVEMENTSANDEXTRA',\n",
       " 'RNN,LSTM,GRU.',\n",
       " 'GOLDMEDALISTMSC',\n",
       " 'JUNIORSDE-MACHINELEARNING',\n",
       " 'JPINFORMATICS',\n",
       " 'FRESHERSYSTEMDEVELOPER',\n",
       " 'CRISONGLOBALSERVICE',\n",
       " 'GRADUATESOFTWAREENGINEER',\n",
       " 'ENGINEERINGIN2019',\n",
       " 'SOFTWARELIFECYCLEWORKSHOP',\n",
       " 'EMPOWEREDTECHNOLOGIES',\n",
       " 'COLLEGEIN2018',\n",
       " 'MATLABPROFESSIONALCERTIFICATE',\n",
       " 'TOTILLDATE',\n",
       " 'B.TECH(ELECTRONICS/TELECOMMUNICATION)FROMBIRLA',\n",
       " 'LTTDIGITALSERVICES',\n",
       " 'SOFTWAREDEVELOPERINTERN',\n",
       " 'BIGDATAANALYST',\n",
       " 'SMARTPARKINGSYSTEM',\n",
       " 'SADHANACONSULTANTS']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74f2a1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_titles = ['EXECUTIVEPROFILE','OTHERACTIVITIES','PERSONALPROFILE','WORKBACKGROUND', 'WORKEXPERIENCE','OTHERQUALIFICATION', 'ACADEMICPROFILE',\n",
    " 'PROFILE','EXPERIENCE','ACTIVITIESANDAWARDS','ACTIVITIES', 'SKILLS' ,'EDUCATION', 'PROJECTS','SUMMARY' ]\n",
    "len(final_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f73a060",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_voc = ['PERSONALPROFILE','PROFILE' , 'SUMMARY' , 'EXECUTIVEPROFILE']\n",
    "education_vocab = ['EDUCATION', 'ACADEMICPROFILE']\n",
    "activities_vocab = ['ACTIVITIESANDAWARDS','OTHERACTIVITIES','ACTIVITIES','OTHERQUALIFICATION', 'PROJECTS']\n",
    "skills_vocab = ['EXPERIENCE', 'SKILLS','WORKBACKGROUND', 'WORKEXPERIENCE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "189bfaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n",
      "0 2\n",
      "2 3\n",
      "0 4\n",
      "4 5\n",
      "0 6\n",
      "2 7\n",
      "0 8\n",
      "3 9\n",
      "4 10\n",
      "0 11\n",
      "0 12\n",
      "0 13\n",
      "2 14\n",
      "0 15\n",
      "3 16\n",
      "0 17\n",
      "3 18\n",
      "4 19\n",
      "0 20\n",
      "3 21\n",
      "4 22\n",
      "0 23\n",
      "3 24\n",
      "0 25\n",
      "2 26\n",
      "0 27\n",
      "4 28\n",
      "4 29\n",
      "0 30\n",
      "0 31\n",
      "0 32\n",
      "2 33\n",
      "0 34\n",
      "3 35\n",
      "4 36\n",
      "2 37\n",
      "0 38\n",
      "0 39\n",
      "3 40\n",
      "0 41\n",
      "4 42\n",
      "2 43\n",
      "0 44\n",
      "3 45\n",
      "4 46\n",
      "2 47\n",
      "3 48\n",
      "0 49\n",
      "3 50\n",
      "4 51\n",
      "2 52\n",
      "3 53\n",
      "0 54\n",
      "4 55\n",
      "4 56\n",
      "3 57\n",
      "0 58\n",
      "0 59\n",
      "3 60\n",
      "0 61\n",
      "2 62\n",
      "4 63\n",
      "0 64\n",
      "4 65\n",
      "0 66\n",
      "4 67\n",
      "0 68\n",
      "4 69\n",
      "2 70\n",
      "3 71\n",
      "3 72\n",
      "0 73\n",
      "0 74\n",
      "4 75\n",
      "3 76\n",
      "0 77\n",
      "0 78\n",
      "3 79\n",
      "4 80\n",
      "3 81\n",
      "0 82\n",
      "4 83\n",
      "3 84\n",
      "3 85\n",
      "2 86\n",
      "0 87\n",
      "0 88\n",
      "4 89\n"
     ]
    }
   ],
   "source": [
    "\n",
    "outliers=0\n",
    "length=0\n",
    "name=''\n",
    "for filename in os.listdir(directory):\n",
    "    length += 1\n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "        education=0\n",
    "        activities=0\n",
    "        skills=0\n",
    "        profile=0\n",
    "        raw = parser.from_file(f)\n",
    "        lines= raw['content'].splitlines()\n",
    "        for line in lines:\n",
    "            for i in profiles_voc:\n",
    "                if(line.count(i)!=0):\n",
    "                    profile=1\n",
    "            for i in education_vocab:\n",
    "                if(line.count(i)!=0):\n",
    "                    education=1\n",
    "            for i in activities_vocab:\n",
    "                if(line.count(i)!=0):\n",
    "                    activities=1\n",
    "            for i in skills_vocab:\n",
    "                if(line.count(i)!=0):\n",
    "                    skills=1\n",
    "        somme=profile+education+activities+skills\n",
    "        if(somme<5):\n",
    "            outliers+=1\n",
    "            print(somme,outliers)\n",
    "            #print(profile,education,activities,skills)\n",
    "            #print(raw['metadata']['resourceName'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc8d78ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0\n"
     ]
    }
   ],
   "source": [
    "outliers=0\n",
    "for line in lines:\n",
    "            for i in profiles_voc:\n",
    "                if(line.count(i)!=0):\n",
    "                    profile=1\n",
    "            for i in education_vocab:\n",
    "                if(line.count(i)!=0):\n",
    "                    education=1\n",
    "            for i in activities_vocab:\n",
    "                if(line.count(i)!=0):\n",
    "                    activities=1\n",
    "            for i in skills_vocab:\n",
    "                if(line.count(i)!=0):\n",
    "                    skills=1\n",
    "somme=profile+education+activities+skills\n",
    "if(somme==2):\n",
    "    outliers+=1\n",
    "print(somme,outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e90c46b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3d2e8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'candidate_149',\n",
       " '',\n",
       " '',\n",
       " 'MIRAD YASTEIN',\n",
       " 'A N A L Y S T  I N T E R N',\n",
       " '',\n",
       " 'SKILLS',\n",
       " '',\n",
       " 'Artificial Intelligence, Deep Learning,',\n",
       " 'Reinforcement Learning, Tensorflow',\n",
       " 'Keras, Scikit learn, Numpy, Pandas,',\n",
       " 'Matplotlib.',\n",
       " '',\n",
       " 'EDUCATION',\n",
       " '',\n",
       " 'B.Tech(IT) from IIIT D&M Kancheepuram, Chennai in 2019',\n",
       " '',\n",
       " 'PERSONAL PROFILE',\n",
       " 'Machine Learning Engineer seeking',\n",
       " 'assignments Deep Learning, Reinforcement',\n",
       " 'Learning, Tensorflow. Keras.',\n",
       " '',\n",
       " 'WORK BACKGROUND',\n",
       " '',\n",
       " 'Larsen & Toubro ',\n",
       " 'Analyst Intern, Dec 2019-Till Date ',\n",
       " '',\n",
       " 'Building OCR Models based on test report data',\n",
       " '',\n",
       " 'OTHER ACTIVITIES',\n",
       " '',\n",
       " 'KSST Scholar',\n",
       " '',\n",
       " 'PROJECTS',\n",
       " '',\n",
       " 'Wesbite Using React ',\n",
       " 'Made a Fully customizable website for',\n",
       " 'a company',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw2 = parser.from_file(r\"C:\\Users\\elyes\\Desktop\\espritAlumni\\HireAMLE\\dataset\\trainResumes\\candidate_002.pdf\")\n",
    "#raw2['content']\n",
    "lines2= raw['content'].splitlines()\n",
    "\n",
    "lines2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f079a8",
   "metadata": {},
   "source": [
    "# Step 3 : Detecting names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f989af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "file = 'ENGivenMale.json'\n",
    "with open(file) as train_file:\n",
    "    dict_trainMale = json.load(train_file)\n",
    "file = 'ENGivenFemale.json'\n",
    "with open(file) as train_file:\n",
    "    dict_trainFemale = json.load(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66a4ec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "namesMale = []\n",
    "for dic in dict_trainMale:\n",
    "    namesMale.append(dic['name'])\n",
    "nameFemale= []   \n",
    "for dic in dict_trainFemale:\n",
    "    nameFemale.append(dic['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5577dcf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4275"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nameFemale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c77b3277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tika import parser\n",
    "# import required module\n",
    "import os\n",
    "directory = r\"C:\\Users\\elyes\\Desktop\\espritAlumni\\HireAMLE\\dataset\\trainResumes\"\n",
    "males=  []\n",
    "for filename in os.listdir(directory):\n",
    "    length += 1\n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "        raw = parser.from_file(f)\n",
    "        lines= raw['content'].splitlines()\n",
    "        i=0\n",
    "        length_lines=len(lines)\n",
    "        found= False\n",
    "        while(i < length_lines and not(found)):\n",
    "            if(lines[i].isupper() and len(lines[i])>1):\n",
    "                males.append(lines[i])\n",
    "                found=True\n",
    "            i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "66cdcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_name(line):\n",
    "    for name in namesMale:\n",
    "        if(line.upper().count(name.upper())!=0):\n",
    "            print(name)\n",
    "            return True\n",
    "    for name in nameFemale:\n",
    "        if(line.upper().count(name.upper())!=0):\n",
    "            print(name)\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "970d97e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JACOB\n",
      "JACOB SMITH\n"
     ]
    }
   ],
   "source": [
    "from tika import parser\n",
    "# import required module\n",
    "import os\n",
    "raw2 = parser.from_file(r\"C:\\Users\\elyes\\Desktop\\espritAlumni\\HireAMLE\\dataset\\trainResumes\\candidate_000.pdf\")\n",
    "lines2= raw2['content'].splitlines()\n",
    "length_lines=len(lines2)\n",
    "found= False\n",
    "i=0\n",
    "while(i < length_lines and not(found)):\n",
    "    if(lines2[i].isupper() and len(lines2[i])>1 and check_name(lines2[i])):\n",
    "        print(lines2[i])\n",
    "        found=True\n",
    "    i+=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6601c9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'candidate_000',\n",
       " '',\n",
       " '',\n",
       " 'JACOB SMITH',\n",
       " 'F R E S H E R',\n",
       " '',\n",
       " 'SKILLS',\n",
       " '',\n",
       " 'Python, SQL, MySQL, Tableau, Power',\n",
       " 'Bi, Pandas , Numpy, Matplotlib, Excel ,',\n",
       " 'Machine Learning, AWS(EMR,EC2,S3),',\n",
       " 'Cloud, Hive(HQL), and Excel',\n",
       " '',\n",
       " 'EDUCATION',\n",
       " '',\n",
       " 'B. Tech, ECE VIT-AP University 2020',\n",
       " '',\n",
       " 'OTHER ACTIVITIES',\n",
       " '',\n",
       " 'Deep Learning Masters',\n",
       " 'Machine Learning',\n",
       " '',\n",
       " 'PROJECTS',\n",
       " '',\n",
       " 'Music Genre Classification ',\n",
       " 'Face, eye, smile recognition',\n",
       " '',\n",
       " 'PERSONAL PROFILE',\n",
       " 'I am actively seeking opportunity as Data',\n",
       " 'Analyst or Machine Learning Engineer.',\n",
       " '',\n",
       " 'My goal is to discover new business',\n",
       " 'strategies and create an impact through',\n",
       " 'data driven analytical decisions and',\n",
       " 'leading the business to success.',\n",
       " '',\n",
       " 'WORK BACKGROUND',\n",
       " '',\n",
       " 'Experts Hub',\n",
       " 'Intern, May 2019',\n",
       " '',\n",
       " 'I was part of a team that designed and developed a smart parking system',\n",
       " 'based on Object Recognition. ',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "37f66574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\elyes\\anaconda3\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\elyes\\anaconda3\\lib\\site-packages (1.20.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab2635a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\elyes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\elyes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\elyes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\elyes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    " \n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "def extract_names(txt):\n",
    "    person_names = []\n",
    " \n",
    "    for sent in nltk.sent_tokenize(txt):\n",
    "        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
    "            if hasattr(chunk, 'label') and chunk.label() == 'PERSON':\n",
    "                person_names.append(\n",
    "                    ' '.join(chunk_leave[0] for chunk_leave in chunk.leaves())\n",
    "                )\n",
    " \n",
    "    return person_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aef4ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elyes', 'Jacob']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person=extract_names('Hello my name is Elyes massoussi i m a data scientist and i work with Jacob on a variety of models in order to predict values')\n",
    "person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e9d01ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#anaconda  prompt.\n",
    "#python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "de9c2450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "NER = spacy.load(\"en_core_web_sm\")\n",
    "text1= NER('Hello my name is Elyes massoussi i m a data scientist and i work with Jacob on a variety of models in order to predict values')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "46a9bf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elyes ORG\n"
     ]
    }
   ],
   "source": [
    "for word in text1.ents:\n",
    "    print(word.text,word.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1fe10fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def find_persons(text):\n",
    "    \n",
    "     # Create Doc object\n",
    "    doc2 = NER(text)\n",
    "    # Identify the persons\n",
    "    persons = [ent.text for ent in doc2.ents if ent.label_ == 'PERSON']\n",
    "    # Return persons\n",
    "    return persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "964edf0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_persons('JENNIFER  loves coding in Python! Jacob ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "60f9939f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\elyes\\\\Desktop\\\\espritAlumni\\\\HireAMLE\\\\dataset\\\\trainResumes\\\\candidate_003.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6352/114796796.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# import required module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mraw2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\elyes\\Desktop\\espritAlumni\\HireAMLE\\dataset\\trainResumes\\candidate_003.pdf\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mfind_persons\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'content'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tika\\parser.py\u001b[0m in \u001b[0;36mfrom_file\u001b[1;34m(filename, serverEndpoint, service, xmlContent, headers, config_path, requestOptions)\u001b[0m\n\u001b[0;32m     38\u001b[0m     '''\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mxmlContent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mservice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserverEndpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequestOptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequestOptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         output = parse1(service, filename, serverEndpoint, services={'meta': '/meta', 'text': '/tika', 'all': '/rmeta/xml'},\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tika\\tika.py\u001b[0m in \u001b[0;36mparse1\u001b[1;34m(option, urlOrPath, serverEndpoint, verbose, tikaServerJar, responseMimeType, services, rawResponse, headers, config_path, requestOptions)\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mservice\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'/tika'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mresponseMimeType\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'text/plain'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Accept'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mresponseMimeType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Content-Disposition'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmake_content_disposition_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0municode_string\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0murlOrPath\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m_is_file_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlOrPath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m         status, response = callServer('put', serverEndpoint, service, f,\n\u001b[0;32m    337\u001b[0m                                       \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtikaServerJar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\elyes\\\\Desktop\\\\espritAlumni\\\\HireAMLE\\\\dataset\\\\trainResumes\\\\candidate_003.pdf'"
     ]
    }
   ],
   "source": [
    "from tika import parser\n",
    "# import required module\n",
    "import os\n",
    "raw2 = parser.from_file(r\"C:\\Users\\elyes\\Desktop\\espritAlumni\\HireAMLE\\dataset\\trainResumes\\candidate_003.pdf\")\n",
    "find_persons(raw2['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "76ca9626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2 \n",
    "    \n",
    "# creating a pdf file object \n",
    "pdfFileObj = open(r\"C:\\Users\\elyes\\Desktop\\espritAlumni\\HireAMLE\\dataset\\trainResumes\\candidate_000.pdf\", 'rb') \n",
    "    \n",
    "# creating a pdf reader object \n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObj) \n",
    "    \n",
    "# printing number of pages in pdf file \n",
    "print(pdfReader.numPages) \n",
    "    \n",
    "# creating a page object \n",
    "pageObj = pdfReader.getPage(0) \n",
    "    \n",
    "# extracting text from page \n",
    "print(pageObj.extractText()) \n",
    "    \n",
    "# closing the pdf file object \n",
    "pdfFileObj.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fab9b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tika import parser\n",
    "# import required module\n",
    "import os\n",
    "raw2 = parser.from_file(r\"C:\\Users\\elyes\\Desktop\\espritAlumni\\HireAMLE\\dataset\\trainResumes\\candidate_001.pdf\")\n",
    "lines2= raw2['content'].splitlines()\n",
    "length_lines=len(lines2)\n",
    "found= False\n",
    "i=0\n",
    "while(i < length_lines and not(found)):\n",
    "    if(lines2[i].isupper() and len(lines2[i])>1 and check_name(lines2[i])):\n",
    "        print(lines2[i])\n",
    "        found=True\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "15b9f97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Machine Learning', 'Computationally Rich']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw2 = parser.from_file(r\"C:\\Users\\elyes\\Desktop\\espritAlumni\\HireAMLE\\dataset\\trainResumes\\candidate_007.pdf\")\n",
    "lines2= raw2['content'].splitlines()\n",
    "find_persons(raw2['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bdcc3d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "while(\"\" in lines2) :\n",
    "    lines2.remove(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7b437374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1eda1d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_candidates= []\n",
    "i=0\n",
    "found=False\n",
    "while(i<len(lines2) and not(found)):\n",
    "    for title in final_titles:\n",
    "        if(lines2[i].upper().replace(\" \",\"\").count(title)!=0):\n",
    "            found=True\n",
    "    name_candidates.append(lines2[i])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5af2b6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['candidate_007', 'ISABELLA REED', 'C O N S U L T A N T  A N A L Y S T', 'SKILLS']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(str(name_candidates))\n",
    "find_persons(str(name_candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1685c6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ISABELLA'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_name=\" \"\n",
    "for name_candidate in name_candidates:\n",
    "    for name in nameFemale:\n",
    "        if(name_candidate.count(name)!=0):\n",
    "            if(len(final_name)<len(name)):\n",
    "                final_name=name\n",
    "final_name            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c0cc3c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tika import parser\n",
    "# import required module\n",
    "import os\n",
    "directory = r\"C:\\Users\\elyes\\Desktop\\espritAlumni\\HireAMLE\\dataset\\trainResumes\"\n",
    "candidates=  []\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "        raw = parser.from_file(f)\n",
    "        lines= raw['content'].splitlines()\n",
    "        while(\"\" in lines) :\n",
    "            lines.remove(\"\")\n",
    "        name_candidates= []\n",
    "        i=0\n",
    "        found=False\n",
    "        while(i<len(lines) and not(found)):\n",
    "            for title in final_titles:\n",
    "                if(lines[i].upper().replace(\" \",\"\").count(title)!=0):\n",
    "                    found=True\n",
    "            name_candidates.append(lines[i])\n",
    "            i+=1\n",
    "        persons=find_persons(str(name_candidates))\n",
    "        if(len(persons)!=0):\n",
    "            candidates.append(persons[0])\n",
    "        else:\n",
    "            final_name=\" \"\n",
    "            for name_candidate in name_candidates:\n",
    "                for name in nameFemale:\n",
    "                    if(name_candidate.count(name)!=0):\n",
    "                        if(len(final_name)<len(name)):\n",
    "                            final_name=name_candidate\n",
    "            candidates.append(final_name)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2b94b93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"JACOB SMITH'\",\n",
       " \"Brianna Williams'\",\n",
       " 'Handling',\n",
       " 'JENNIFER ARMSTRONG',\n",
       " 'ISABELLA REED',\n",
       " \"Mia Park'\",\n",
       " 'College Bangalore',\n",
       " ' ',\n",
       " ' ',\n",
       " 'JIMMY GARTNER',\n",
       " \"ANTHONY GUAP'\",\n",
       " \"John Allen'\",\n",
       " 'BAKER',\n",
       " ' ',\n",
       " \"Daniel Lopez'\",\n",
       " 'ANALYST',\n",
       " ' ',\n",
       " 'PROFESSIONAL PROFILE',\n",
       " 'AUDREY COLESON',\n",
       " 'GAVING WILSON',\n",
       " 'SOFTWARE DEVELOPER & ANALYST ML',\n",
       " 'NOLAN CLARK',\n",
       " 'MADELYN MILNER',\n",
       " 'JUNIOR SDE-MACHINE LEARNING',\n",
       " ' ',\n",
       " ' ',\n",
       " 'STACEY BELARNY',\n",
       " 'HOWARD GOODMAN',\n",
       " 'CAROLIN BANKS',\n",
       " ' ',\n",
       " 'MASON MARKINOV',\n",
       " ' ',\n",
       " 'TRAINEE, MAY 2019-OCT 2019 ',\n",
       " 'MAYA HAYDEN',\n",
       " 'OWEN SHAW',\n",
       " 'MIKAYLA NEUER',\n",
       " ' ',\n",
       " 'Joseline',\n",
       " 'DAMIAN ROSSIER',\n",
       " 'GRADUATE SOFTWARE ENGINEER',\n",
       " ' ',\n",
       " \"MICHAEL REEVER'\",\n",
       " \"Publicis Sapient'\",\n",
       " \"Jeremy Nyugen '\",\n",
       " 'DATA ANALYST',\n",
       " 'candidate_074',\n",
       " \"Remiro Amio '\",\n",
       " 'JUNIOR ENGINEER',\n",
       " ' ',\n",
       " 'ASHLEY HAYDON',\n",
       " 'BETHANY CUMMINS',\n",
       " ' ',\n",
       " 'ASSOCIATE CONSULTANT',\n",
       " ' ',\n",
       " \"JOSE GARCIA'\",\n",
       " 'HELENA PATRICKS',\n",
       " 'DATA SCIENTIST',\n",
       " 'SYDNEY JONES',\n",
       " ' ',\n",
       " 'JUNIOR MACHINE LEARNING ENGINEER',\n",
       " ' ',\n",
       " 'Data Analysis, EDA and modelling of the secondary',\n",
       " 'JEREMY WANG',\n",
       " \"Pierre Franks'\",\n",
       " 'AMBER GREEN',\n",
       " 'BILL CLIFFORD',\n",
       " 'TAYLOR BENLEY',\n",
       " \"Ellie Mackey'\",\n",
       " 'JAYLA RAMIREZ',\n",
       " 'Blockchain Analyst',\n",
       " 'FRESHER INTERN',\n",
       " 'Trainee Intern',\n",
       " 'LISA JENNINGS',\n",
       " ' ',\n",
       " \"NICHOLAS MENDES'\",\n",
       " \"Mohantpur 2018 '\",\n",
       " ' ',\n",
       " ' ',\n",
       " 'SOFTWARE DEVELOPER INTERN',\n",
       " 'SHAWN BUFFET',\n",
       " 'Kanpur',\n",
       " 'Thatcher',\n",
       " 'KELSEY STENS',\n",
       " 'JUNIOR DEVELOPER',\n",
       " 'BENJAMIN OSTA',\n",
       " ' ',\n",
       " \"Jaroslav Chechnik'\",\n",
       " ' ',\n",
       " 'MIRAD YASTEIN']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc1589d",
   "metadata": {},
   "source": [
    "# Step 4: Detecting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8ecd364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0526367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(0, \"Name\", False)\n",
    "df.insert(1,\"Description\",False)\n",
    "df.insert(2, \"Skills\", False)\n",
    "df.insert(3, \"Education\", False)\n",
    "df.insert(4, \"Activities\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "41687304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Education</th>\n",
       "      <th>Activities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name, Description, Skills, Education, Activities]\n",
       "Index: []"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "98b57d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_voc = ['PERSONALPROFILE','PROFILE' , 'SUMMARY' , 'EXECUTIVEPROFILE']\n",
    "education_vocab = ['EDUCATION', 'ACADEMICPROFILE']\n",
    "activities_vocab = ['ACTIVITIESANDAWARDS','OTHERACTIVITIES','ACTIVITIES','OTHERQUALIFICATION', 'PROJECTS']\n",
    "skills_vocab = ['EXPERIENCE', 'SKILLS','WORKBACKGROUND', 'WORKEXPERIENCE']\n",
    "from tika import parser\n",
    "# import required module\n",
    "import os\n",
    "directory = r\"C:\\Users\\elyes\\Desktop\\espritAlumni\\HireAMLE\\dataset\\trainResumes\"\n",
    "index=0\n",
    "for filename in os.listdir(directory):\n",
    "    index+=1\n",
    "    f = os.path.join(directory, filename)\n",
    "    row={'name':' ',\n",
    "    'description':' ',\n",
    "    'skills':' ',\n",
    "    'education':' ',\n",
    "    'activities':' '}\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "        raw = parser.from_file(f)\n",
    "        lines= raw['content'].splitlines()\n",
    "        while(\"\" in lines) :\n",
    "            lines.remove(\"\")\n",
    "        name_candidates= []\n",
    "        i=0\n",
    "        found=False\n",
    "        while(i<len(lines) and not(found)):\n",
    "            for title in final_titles:\n",
    "                if(lines[i].upper().replace(\" \",\"\").count(title)!=0):\n",
    "                    found=True\n",
    "            name_candidates.append(lines[i])\n",
    "            i+=1\n",
    "        persons=find_persons(str(name_candidates))\n",
    "        if(len(persons)!=0):\n",
    "            row['name']=persons[0]\n",
    "        else:\n",
    "            final_name=\" \"\n",
    "            for name_candidate in name_candidates:\n",
    "                for name in nameFemale:\n",
    "                    if(name_candidate.count(name)!=0):\n",
    "                        if(len(final_name)<len(name)):\n",
    "                            final_name=name_candidate\n",
    "            row['name']=final_name\n",
    "        start=False\n",
    "        feature='name'\n",
    "        found=False\n",
    "        for line in lines:\n",
    "            for word in profiles_voc:\n",
    "                if(line.upper().replace(\" \",\"\").count(word)!=0):\n",
    "                    start=True\n",
    "                    feature='description'\n",
    "                    found=True\n",
    "            if(True):\n",
    "                for word in education_vocab:\n",
    "                    if(line.upper().replace(\" \",\"\").count(word)!=0):\n",
    "                        start=True\n",
    "                        feature='education'\n",
    "                        found=True\n",
    "            if(True):\n",
    "                for word in activities_vocab:\n",
    "                    if(line.upper().replace(\" \",\"\").count(word)!=0):\n",
    "                        start=True\n",
    "                        feature='activities'\n",
    "                        found=True\n",
    "            if(True):\n",
    "                for word in skills_vocab:\n",
    "                    if(line.upper().replace(\" \",\"\").count(word)!=0):\n",
    "                        start=True\n",
    "                        feature='skills'\n",
    "                        found=True  \n",
    "            if(start):\n",
    "                row[feature] = row[feature] + ' ' + line\n",
    "        df.loc[index] = [row['name'],row['description'],row['skills'],row['education'],row['activities']]\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e4182b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Education</th>\n",
       "      <th>Activities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JACOB SMITH'</td>\n",
       "      <td>PERSONAL PROFILE I am actively seeking oppor...</td>\n",
       "      <td>SKILLS Python, SQL, MySQL, Tableau, Power Bi...</td>\n",
       "      <td>EDUCATION B. Tech, ECE VIT-AP University 2020</td>\n",
       "      <td>OTHER ACTIVITIES Deep Learning Masters Machi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brianna Williams'</td>\n",
       "      <td>Executive Profile A curiosity-driven data sc...</td>\n",
       "      <td>thinking and analytical skills towards the c...</td>\n",
       "      <td>Education BSc(CA) MamCO University Kerala, 2...</td>\n",
       "      <td>Other Activities Trained in Big Data Analysi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Handling</td>\n",
       "      <td></td>\n",
       "      <td>WORK EXPERIENCE Certified Data analyst with ...</td>\n",
       "      <td>EDUCATION MASON QUADRADO ASSOCIATE ANALYST</td>\n",
       "      <td>OTHER QUALIFICATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JENNIFER ARMSTRONG</td>\n",
       "      <td>P R O F I L E Fresher Computer vision and Ma...</td>\n",
       "      <td>S K I L L S Machine learning, Deep learning,...</td>\n",
       "      <td>E D U C A T I O N B.Tech Computer Science fr...</td>\n",
       "      <td>A C T I V I T I E S Distinction medalist.  H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ISABELLA REED</td>\n",
       "      <td>PERSONAL PROFILE Interested in Computational...</td>\n",
       "      <td>SKILLS Data Science, Machine Learning, Busin...</td>\n",
       "      <td>EDUCATION B.Tech(Computer Science) RCC IT, K...</td>\n",
       "      <td>OTHER ACTIVITIES Introduction to Python [Dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>BENJAMIN OSTA</td>\n",
       "      <td>PROFESSIONAL PROFILE As a fresher I have in ...</td>\n",
       "      <td>PROFICIENT SKILLS Software Engineer, Softwar...</td>\n",
       "      <td>EDUCATIONAL HISTORY  B.Tech(Civil) from Anna...</td>\n",
       "      <td>learning models to real-life projects.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>WORK EXPERIENCE Big data analytics working a...</td>\n",
       "      <td>EDUCATION JEROME PELINSKY BIG DATA ANALYST</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Jaroslav Chechnik'</td>\n",
       "      <td>Executive Profile Looking for a job opportun...</td>\n",
       "      <td>Skills Python, Anaconda, NumPy, Pandas, Matp...</td>\n",
       "      <td>Education B. Tech, ECE VIT-AP University 2021</td>\n",
       "      <td>Other Activities Deep Learning Masters  Mach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td></td>\n",
       "      <td>P R O F I L E</td>\n",
       "      <td>A data science professional with 1 years of ...</td>\n",
       "      <td>E D U C A T I O N B.TECH/B.E. (COMPUTERS) FR...</td>\n",
       "      <td>P R O J E C T S Transformer based Question A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>MIRAD YASTEIN</td>\n",
       "      <td>PERSONAL PROFILE Machine Learning Engineer s...</td>\n",
       "      <td>SKILLS Artificial Intelligence, Deep Learnin...</td>\n",
       "      <td>EDUCATION B.Tech(IT) from IIIT D&amp;M Kancheepu...</td>\n",
       "      <td>OTHER ACTIVITIES KSST Scholar PROJECTS Wesbi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name                                        Description  \\\n",
       "1         JACOB SMITH'    PERSONAL PROFILE I am actively seeking oppor...   \n",
       "2    Brianna Williams'    Executive Profile A curiosity-driven data sc...   \n",
       "3             Handling                                                      \n",
       "4   JENNIFER ARMSTRONG    P R O F I L E Fresher Computer vision and Ma...   \n",
       "5        ISABELLA REED    PERSONAL PROFILE Interested in Computational...   \n",
       "..                 ...                                                ...   \n",
       "85       BENJAMIN OSTA    PROFESSIONAL PROFILE As a fresher I have in ...   \n",
       "86                                                                          \n",
       "87  Jaroslav Chechnik'    Executive Profile Looking for a job opportun...   \n",
       "88                                                          P R O F I L E   \n",
       "89       MIRAD YASTEIN    PERSONAL PROFILE Machine Learning Engineer s...   \n",
       "\n",
       "                                               Skills  \\\n",
       "1     SKILLS Python, SQL, MySQL, Tableau, Power Bi...   \n",
       "2     thinking and analytical skills towards the c...   \n",
       "3     WORK EXPERIENCE Certified Data analyst with ...   \n",
       "4     S K I L L S Machine learning, Deep learning,...   \n",
       "5     SKILLS Data Science, Machine Learning, Busin...   \n",
       "..                                                ...   \n",
       "85    PROFICIENT SKILLS Software Engineer, Softwar...   \n",
       "86    WORK EXPERIENCE Big data analytics working a...   \n",
       "87    Skills Python, Anaconda, NumPy, Pandas, Matp...   \n",
       "88    A data science professional with 1 years of ...   \n",
       "89    SKILLS Artificial Intelligence, Deep Learnin...   \n",
       "\n",
       "                                            Education  \\\n",
       "1       EDUCATION B. Tech, ECE VIT-AP University 2020   \n",
       "2     Education BSc(CA) MamCO University Kerala, 2...   \n",
       "3          EDUCATION MASON QUADRADO ASSOCIATE ANALYST   \n",
       "4     E D U C A T I O N B.Tech Computer Science fr...   \n",
       "5     EDUCATION B.Tech(Computer Science) RCC IT, K...   \n",
       "..                                                ...   \n",
       "85    EDUCATIONAL HISTORY  B.Tech(Civil) from Anna...   \n",
       "86         EDUCATION JEROME PELINSKY BIG DATA ANALYST   \n",
       "87      Education B. Tech, ECE VIT-AP University 2021   \n",
       "88    E D U C A T I O N B.TECH/B.E. (COMPUTERS) FR...   \n",
       "89    EDUCATION B.Tech(IT) from IIIT D&M Kancheepu...   \n",
       "\n",
       "                                           Activities  \n",
       "1     OTHER ACTIVITIES Deep Learning Masters Machi...  \n",
       "2     Other Activities Trained in Big Data Analysi...  \n",
       "3                                 OTHER QUALIFICATION  \n",
       "4     A C T I V I T I E S Distinction medalist.  H...  \n",
       "5     OTHER ACTIVITIES Introduction to Python [Dat...  \n",
       "..                                                ...  \n",
       "85             learning models to real-life projects.  \n",
       "86                                                     \n",
       "87    Other Activities Deep Learning Masters  Mach...  \n",
       "88    P R O J E C T S Transformer based Question A...  \n",
       "89    OTHER ACTIVITIES KSST Scholar PROJECTS Wesbi...  \n",
       "\n",
       "[89 rows x 5 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "33312580",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_voc = ['PERSONALPROFILE','PROFILE' , 'SUMMARY' , 'EXECUTIVEPROFILE']\n",
    "education_vocab = ['EDUCATION', 'ACADEMICPROFILE']\n",
    "activities_vocab = ['ACTIVITIESANDAWARDS','OTHERACTIVITIES','ACTIVITIES','OTHERQUALIFICATION', 'PROJECTS']\n",
    "skills_vocab = ['EXPERIENCE', 'SKILLS','WORKBACKGROUND', 'WORKEXPERIENCE']\n",
    "from tika import parser\n",
    "# import required module\n",
    "import os\n",
    "directory = r\"C:\\Users\\elyes\\Desktop\\espritAlumni\\HireAMLE\\dataset\\trainResumes\"\n",
    "index=0\n",
    "for filename in os.listdir(directory):\n",
    "    index+=1\n",
    "    f = os.path.join(directory, filename)\n",
    "    row={'name':' ',\n",
    "    'description':' ',\n",
    "    'skills':' ',\n",
    "    'education':' ',\n",
    "    'activities':' '}\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "        raw = parser.from_file(f)\n",
    "        lines= raw['content'].splitlines()\n",
    "        while(\"\" in lines) :\n",
    "            lines.remove(\"\")\n",
    "        name_candidates= []\n",
    "        i=0\n",
    "        found=False\n",
    "        while(i<len(lines) and not(found)):\n",
    "            for title in final_titles:\n",
    "                if(lines[i].upper().replace(\" \",\"\").count(title)!=0):\n",
    "                    found=True\n",
    "            name_candidates.append(lines[i])\n",
    "            i+=1\n",
    "        persons=find_persons(str(name_candidates))\n",
    "        if(len(persons)!=0):\n",
    "            row['name']=persons[0]\n",
    "        else:\n",
    "            final_name=\" \"\n",
    "            for name_candidate in name_candidates:\n",
    "                for name in nameFemale:\n",
    "                    if(name_candidate.count(name)!=0):\n",
    "                        if(len(final_name)<len(name)):\n",
    "                            final_name=name_candidate\n",
    "            row['name']=final_name\n",
    "        start=False\n",
    "        feature='name'\n",
    "        found=False\n",
    "        skip=False\n",
    "        for line in lines:\n",
    "            for word in profiles_voc:\n",
    "                if(line.upper().replace(\" \",\"\").count(word)!=0):\n",
    "                    start=True\n",
    "                    feature='description'\n",
    "                    found=True\n",
    "                    skip=True\n",
    "            if(True):\n",
    "                for word in education_vocab:\n",
    "                    if(line.upper().replace(\" \",\"\").count(word)!=0):\n",
    "                        start=True\n",
    "                        feature='education'\n",
    "                        found=True\n",
    "                        skip=True\n",
    "            if(True):\n",
    "                for word in activities_vocab:\n",
    "                    if(line.upper().replace(\" \",\"\").count(word)!=0):\n",
    "                        start=True\n",
    "                        feature='activities'\n",
    "                        found=True\n",
    "                        skip=True\n",
    "            if(True):\n",
    "                for word in skills_vocab:\n",
    "                    if(line.upper().replace(\" \",\"\").count(word)!=0):\n",
    "                        start=True\n",
    "                        feature='skills'\n",
    "                        found=True  \n",
    "                        skip=True\n",
    "            if(start):\n",
    "                if(skip):\n",
    "                    skip=False\n",
    "                else:\n",
    "                    row[feature] = row[feature] + ' ' + line\n",
    "        df.loc[index] = [row['name'],row['description'],row['skills'],row['education'],row['activities']]\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "755acfa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Education</th>\n",
       "      <th>Activities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JACOB SMITH'</td>\n",
       "      <td>I am actively seeking opportunity as Data An...</td>\n",
       "      <td>Python, SQL, MySQL, Tableau, Power Bi, Panda...</td>\n",
       "      <td>B. Tech, ECE VIT-AP University 2020</td>\n",
       "      <td>Deep Learning Masters Machine Learning Music...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brianna Williams'</td>\n",
       "      <td>A curiosity-driven data scientist, eager to ...</td>\n",
       "      <td>consistent growth and development of the org...</td>\n",
       "      <td>BSc(CA) MamCO University Kerala, 2018  MSc(C...</td>\n",
       "      <td>Trained in Big Data Analysis Hadoop A-1 Leve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Handling</td>\n",
       "      <td></td>\n",
       "      <td>data with good numerical accuracy.  Python, ...</td>\n",
       "      <td>MASON QUADRADO ASSOCIATE ANALYST</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JENNIFER ARMSTRONG</td>\n",
       "      <td>Fresher Computer vision and Machine Learning...</td>\n",
       "      <td>Machine learning, Deep learning, Computer vi...</td>\n",
       "      <td>B.Tech Computer Science from IIT Guwahati, 2...</td>\n",
       "      <td>Distinction medalist.  Honorary member of St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ISABELLA REED</td>\n",
       "      <td>Interested in Computationally Rich problems....</td>\n",
       "      <td>Data Science, Machine Learning, Business Ana...</td>\n",
       "      <td>B.Tech(Computer Science) RCC IT, Kolkata 201...</td>\n",
       "      <td>Introduction to Python [Datacamp]  Machine L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>BENJAMIN OSTA</td>\n",
       "      <td>As a fresher I have in the field of Software...</td>\n",
       "      <td>Software Engineer, Software Developer, C++, ...</td>\n",
       "      <td>B.Tech(Civil) from Anna University in 2020</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>also used multiple cloud infrastructure serv...</td>\n",
       "      <td>JEROME PELINSKY BIG DATA ANALYST</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Jaroslav Chechnik'</td>\n",
       "      <td>Looking for a job opportunity in which I can...</td>\n",
       "      <td>Python, Anaconda, NumPy, Pandas, Matplotlib,...</td>\n",
       "      <td>B. Tech, ECE VIT-AP University 2021</td>\n",
       "      <td>Deep Learning Masters  Machine Learning  Mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>building and deploying end-to-end analytical...</td>\n",
       "      <td>B.TECH/B.E. (COMPUTERS) FROM RAJIV GANDHI PR...</td>\n",
       "      <td>Transformer based Question Answering Chatbot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>MIRAD YASTEIN</td>\n",
       "      <td>Machine Learning Engineer seeking assignment...</td>\n",
       "      <td>Artificial Intelligence, Deep Learning, Rein...</td>\n",
       "      <td>B.Tech(IT) from IIIT D&amp;M Kancheepuram, Chenn...</td>\n",
       "      <td>KSST Scholar Wesbite Using React  Made a Ful...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name                                        Description  \\\n",
       "1         JACOB SMITH'    I am actively seeking opportunity as Data An...   \n",
       "2    Brianna Williams'    A curiosity-driven data scientist, eager to ...   \n",
       "3             Handling                                                      \n",
       "4   JENNIFER ARMSTRONG    Fresher Computer vision and Machine Learning...   \n",
       "5        ISABELLA REED    Interested in Computationally Rich problems....   \n",
       "..                 ...                                                ...   \n",
       "85       BENJAMIN OSTA    As a fresher I have in the field of Software...   \n",
       "86                                                                          \n",
       "87  Jaroslav Chechnik'    Looking for a job opportunity in which I can...   \n",
       "88                                                                          \n",
       "89       MIRAD YASTEIN    Machine Learning Engineer seeking assignment...   \n",
       "\n",
       "                                               Skills  \\\n",
       "1     Python, SQL, MySQL, Tableau, Power Bi, Panda...   \n",
       "2     consistent growth and development of the org...   \n",
       "3     data with good numerical accuracy.  Python, ...   \n",
       "4     Machine learning, Deep learning, Computer vi...   \n",
       "5     Data Science, Machine Learning, Business Ana...   \n",
       "..                                                ...   \n",
       "85    Software Engineer, Software Developer, C++, ...   \n",
       "86    also used multiple cloud infrastructure serv...   \n",
       "87    Python, Anaconda, NumPy, Pandas, Matplotlib,...   \n",
       "88    building and deploying end-to-end analytical...   \n",
       "89    Artificial Intelligence, Deep Learning, Rein...   \n",
       "\n",
       "                                            Education  \\\n",
       "1                 B. Tech, ECE VIT-AP University 2020   \n",
       "2     BSc(CA) MamCO University Kerala, 2018  MSc(C...   \n",
       "3                    MASON QUADRADO ASSOCIATE ANALYST   \n",
       "4     B.Tech Computer Science from IIT Guwahati, 2...   \n",
       "5     B.Tech(Computer Science) RCC IT, Kolkata 201...   \n",
       "..                                                ...   \n",
       "85         B.Tech(Civil) from Anna University in 2020   \n",
       "86                   JEROME PELINSKY BIG DATA ANALYST   \n",
       "87                B. Tech, ECE VIT-AP University 2021   \n",
       "88    B.TECH/B.E. (COMPUTERS) FROM RAJIV GANDHI PR...   \n",
       "89    B.Tech(IT) from IIIT D&M Kancheepuram, Chenn...   \n",
       "\n",
       "                                           Activities  \n",
       "1     Deep Learning Masters Machine Learning Music...  \n",
       "2     Trained in Big Data Analysis Hadoop A-1 Leve...  \n",
       "3                                                      \n",
       "4     Distinction medalist.  Honorary member of St...  \n",
       "5     Introduction to Python [Datacamp]  Machine L...  \n",
       "..                                                ...  \n",
       "85                                                     \n",
       "86                                                     \n",
       "87    Deep Learning Masters  Machine Learning  Mus...  \n",
       "88       Transformer based Question Answering Chatbot  \n",
       "89    KSST Scholar Wesbite Using React  Made a Ful...  \n",
       "\n",
       "[89 rows x 5 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
