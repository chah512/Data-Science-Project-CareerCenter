{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1O-6OPbI-f7a",
    "outputId": "99bd073b-82b1-4593-a022-4ff7677abe6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['linkedinProfile', 'email', 'description', 'headline', 'location',\n",
       "       'imgUrl', 'firstName', 'lastName', 'fullName', 'subscribers',\n",
       "       'connectionDegree', 'vmid', 'userId', 'linkedinSalesNavigatorUrl',\n",
       "       'connectionsUrl', 'mutualConnectionsUrl', 'mutualConnectionsText',\n",
       "       'company', 'companyUrl', 'jobTitle', 'jobLocation', 'jobDateRange',\n",
       "       'school', 'schoolDegree', 'schoolDateRange', 'allSkills', 'skill1',\n",
       "       'endorsement1', 'skill2', 'endorsement2', 'skill3', 'endorsement3',\n",
       "       'skill4', 'endorsement4', 'skill5', 'endorsement5', 'baseUrl',\n",
       "       'profileId', 'timestamp', 'jobDescription', 'company2', 'companyUrl2',\n",
       "       'jobTitle2', 'jobLocation2', 'jobDateRange2', 'schoolUrl', 'school2',\n",
       "       'schoolDegree2', 'schoolDateRange2', 'skill6', 'endorsement6',\n",
       "       'connectionsCount', 'schoolUrl2', 'birthday', 'mail',\n",
       "       'schoolDescription2', 'jobDescription2', 'schoolDescription', 'website',\n",
       "       'connectedOn', 'twitter', 'facebookUrl', 'error', 'phoneNumber'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel(\"elyes.xlsx\")\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dZltw96iA2ry",
    "outputId": "ecfe4a39-a9a9-470f-bc44-85310bb1f450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from textblob) (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.4)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.17.1\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7UxLjRzAI810",
    "outputId": "f6f15c5c-e737-42df-96d6-e4dd8165a68b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autocorrect\n",
      "  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n",
      "Building wheels for collected packages: autocorrect\n",
      "  Building wheel for autocorrect (setup.py): started\n",
      "  Building wheel for autocorrect (setup.py): finished with status 'done'\n",
      "  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622381 sha256=d5a902a9348b609d46d790e50201efb4b7627dbf3d17484f7a65c7da9c61e5e5\n",
      "  Stored in directory: c:\\users\\elyes\\appdata\\local\\pip\\cache\\wheels\\ab\\0f\\23\\3c010c3fd877b962146e7765f9e9b08026cac8b035094c5750\n",
      "Successfully built autocorrect\n",
      "Installing collected packages: autocorrect\n",
      "Successfully installed autocorrect-2.6.1\n",
      "Collecting pyspellchecker\n",
      "  Downloading pyspellchecker-0.6.3-py3-none-any.whl (2.7 MB)\n",
      "Installing collected packages: pyspellchecker\n",
      "Successfully installed pyspellchecker-0.6.3\n",
      "Collecting pattern\n",
      "  Downloading Pattern-3.6.0.tar.gz (22.2 MB)\n",
      "Requirement already satisfied: future in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from pattern) (0.18.2)\n",
      "Collecting backports.csv\n",
      "  Downloading backports.csv-1.0.7-py2.py3-none-any.whl (12 kB)\n",
      "Collecting mysqlclient\n",
      "  Downloading mysqlclient-2.1.0-cp39-cp39-win_amd64.whl (180 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from pattern) (4.10.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from pattern) (4.6.3)\n",
      "Collecting feedparser\n",
      "  Downloading feedparser-6.0.8-py3-none-any.whl (81 kB)\n",
      "Collecting pdfminer.six\n",
      "  Downloading pdfminer.six-20220319-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from pattern) (1.20.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from pattern) (1.7.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from pattern) (3.6.5)\n",
      "Collecting python-docx\n",
      "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
      "Collecting cherrypy\n",
      "  Downloading CherryPy-18.6.1-py2.py3-none-any.whl (419 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from pattern) (2.26.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from beautifulsoup4->pattern) (2.2.1)\n",
      "Collecting cheroot>=8.2.1\n",
      "  Downloading cheroot-8.6.0-py2.py3-none-any.whl (104 kB)\n",
      "Collecting zc.lockfile\n",
      "  Downloading zc.lockfile-2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting portend>=2.1.1\n",
      "  Downloading portend-3.1.0-py3-none-any.whl (5.3 kB)\n",
      "Collecting jaraco.collections\n",
      "  Downloading jaraco.collections-3.5.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from cherrypy->pattern) (8.10.0)\n",
      "Requirement already satisfied: pywin32>=227 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from cherrypy->pattern) (228)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from cheroot>=8.2.1->cherrypy->pattern) (1.16.0)\n",
      "Collecting jaraco.functools\n",
      "  Downloading jaraco.functools-3.5.0-py3-none-any.whl (7.0 kB)\n",
      "Collecting tempora>=1.8\n",
      "  Downloading tempora-5.0.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: pytz in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern) (2021.3)\n",
      "Collecting sgmllib3k\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "Collecting jaraco.classes\n",
      "  Downloading jaraco.classes-3.2.1-py3-none-any.whl (5.6 kB)\n",
      "Collecting jaraco.text\n",
      "  Downloading jaraco.text-3.7.0-py3-none-any.whl (8.6 kB)\n",
      "Collecting jaraco.context>=4.1\n",
      "  Downloading jaraco.context-4.1.1-py3-none-any.whl (4.4 kB)\n",
      "Requirement already satisfied: click in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from nltk->pattern) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from nltk->pattern) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from nltk->pattern) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from nltk->pattern) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from click->nltk->pattern) (0.4.4)\n",
      "Requirement already satisfied: chardet in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from pdfminer.six->pattern) (3.0.4)\n",
      "Requirement already satisfied: cryptography in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from pdfminer.six->pattern) (3.4.8)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from cryptography->pdfminer.six->pattern) (1.14.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography->pdfminer.six->pattern) (2.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from requests->pattern) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from requests->pattern) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from requests->pattern) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from requests->pattern) (2.10)\n",
      "Requirement already satisfied: setuptools in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from zc.lockfile->cherrypy->pattern) (58.0.4)\n",
      "Building wheels for collected packages: pattern, python-docx, sgmllib3k\n",
      "  Building wheel for pattern (setup.py): started\n",
      "  Building wheel for pattern (setup.py): finished with status 'done'\n",
      "  Created wheel for pattern: filename=Pattern-3.6-py3-none-any.whl size=22332721 sha256=eea7ccfd9a00dbe54647f15ce0150664dc95557b1317e8aedd86b679b84d1c79\n",
      "  Stored in directory: c:\\users\\elyes\\appdata\\local\\pip\\cache\\wheels\\50\\33\\f3\\ea00b80d50c09f210588bda15ec60bdb38b289b452577cd5c3\n",
      "  Building wheel for python-docx (setup.py): started\n",
      "  Building wheel for python-docx (setup.py): finished with status 'done'\n",
      "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184508 sha256=cb5e3af1221fc39de03dcd21d14759ad08d2278bfa5a3e314a43c5acbb90dfcb\n",
      "  Stored in directory: c:\\users\\elyes\\appdata\\local\\pip\\cache\\wheels\\83\\8b\\7c\\09ae60c42c7ba4ed2dddaf2b8b9186cb105255856d6ed3dba5\n",
      "  Building wheel for sgmllib3k (setup.py): started\n",
      "  Building wheel for sgmllib3k (setup.py): finished with status 'done'\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6065 sha256=91478a19cb0d48d451a3d510cc63c083879736cb53bd7dedccdcd9e4c59cc960\n",
      "  Stored in directory: c:\\users\\elyes\\appdata\\local\\pip\\cache\\wheels\\65\\7a\\a7\\78c287f64e401255dff4c13fdbc672fed5efbfd21c530114e1\n",
      "Successfully built pattern python-docx sgmllib3k\n",
      "Installing collected packages: jaraco.functools, jaraco.context, tempora, jaraco.text, jaraco.classes, zc.lockfile, sgmllib3k, portend, jaraco.collections, cheroot, python-docx, pdfminer.six, mysqlclient, feedparser, cherrypy, backports.csv, pattern\n",
      "Successfully installed backports.csv-1.0.7 cheroot-8.6.0 cherrypy-18.6.1 feedparser-6.0.8 jaraco.classes-3.2.1 jaraco.collections-3.5.1 jaraco.context-4.1.1 jaraco.functools-3.5.0 jaraco.text-3.7.0 mysqlclient-2.1.0 pattern-3.6 pdfminer.six-20220319 portend-3.1.0 python-docx-0.8.11 sgmllib3k-1.0.0 tempora-5.0.1 zc.lockfile-2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install autocorrect\n",
    "!pip install pyspellchecker\n",
    "!pip install pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "t5DqmquJJ33E"
   },
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "u3waQn0pKjZ7"
   },
   "outputs": [],
   "source": [
    "docx=[\"ther is somting rong wit thi frase\",\"victori\",\"watich\",\"kiys\",\"mowse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9XGvOEVfK0-L",
    "outputId": "fb5bb00e-55c3-4292-b37d-ff2c61651f1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ther is somting rong wit thi frase:ther is somting rong wit thi frase\n",
      "victori:victory\n",
      "watich:watch\n",
      "kiys:kids\n",
      "mowse:mouse\n"
     ]
    }
   ],
   "source": [
    "spell = SpellChecker()\n",
    "for word in docx:\n",
    "    print(f'{word}:{spell.correction(word)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "urfOL2ywLdN1",
    "outputId": "0feeabec-c168-4074-892c-f9baea8d7253"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ther is somting rong wit thi frase:{'ther is somting rong wit thi frase'}\n",
      "victori:{'victory', 'victor', 'victors', 'victoria', 'vittori'}\n",
      "watich:{'watch'}\n",
      "kiys:{\"ki's\", 'keys', 'kis', 'kits', 'kins', 'kiss', 'kils', 'kids', 'kips'}\n",
      "mowse:{'mows', 'dowse', 'mouse', 'mose', 'morse', 'moose'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for word in docx:\n",
    "    print(f'{word}:{spell.candidates(word)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4TYnQNzlMtgT"
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob,Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cOx13h03MzY8",
    "outputId": "e46b7ce9-6c7d-472b-dbdc-26fad0f6263d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textdistance in c:\\users\\elyes\\anaconda3\\lib\\site-packages (4.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install textdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E0yphWv-hTJM",
    "outputId": "09e88f4b-fe02-49c5-e14e-06882608c8bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top ten words in the text are:['the', 'project', 'gutenberg', 'ebook', 'of', 'moby', 'dick', 'or', 'the', 'whale']\n",
      "Total Unique words are 17647.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textdistance\n",
    "import re\n",
    "from collections import Counter\n",
    "words = []\n",
    "with open('book.txt', 'r', encoding=\"utf8\") as f:\n",
    "    file_name_data = f.read()\n",
    "    file_name_data=file_name_data.lower()\n",
    "    words = re.findall('\\w+',file_name_data)\n",
    "# This is our vocabulary\n",
    "V = set(words)\n",
    "print(f\"Top ten words in the text are:{words[0:10]}\")\n",
    "print(f\"Total Unique words are {len(V)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fIGm_sr_i-cN",
    "outputId": "988ba3b4-8f1b-404e-8ee4-6432993cb438"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 14703), ('of', 6742), ('and', 6517), ('a', 4799), ('to', 4707), ('in', 4238), ('that', 3081), ('it', 2534), ('his', 2530), ('i', 2120)]\n"
     ]
    }
   ],
   "source": [
    "word_freq = {}  \n",
    "word_freq = Counter(words)\n",
    "print(word_freq.most_common()[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "p4E-rw-fj5kb"
   },
   "outputs": [],
   "source": [
    "probs = {}     \n",
    "Total = sum(word_freq.values())    \n",
    "for k in word_freq.keys():\n",
    "    probs[k] = word_freq[k]/Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "1q-ZOzebkXu1"
   },
   "outputs": [],
   "source": [
    "def my_autocorrect(input_word):\n",
    "    input_word = input_word.lower()\n",
    "    if input_word in V:\n",
    "        return input_word\n",
    "    else:\n",
    "        sim = [1-(textdistance.Jaccard(qval=2).distance(v,input_word)) for v in word_freq.keys()]\n",
    "        df = pd.DataFrame.from_dict(probs, orient='index').reset_index()\n",
    "        df = df.rename(columns={'index':'Word', 0:'Prob'})\n",
    "        df['Similarity'] = sim\n",
    "        output = df.sort_values(['Similarity', 'Prob'], ascending=False).head()\n",
    "        print(output)\n",
    "        return(output.Word.iat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Hs4i_6BxlGVi"
   },
   "outputs": [],
   "source": [
    "def autocorrect(text):\n",
    "    words = re.findall('\\w+',text)\n",
    "    result =''\n",
    "    for word in words:\n",
    "        result=result +' '+ my_autocorrect(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "pWgiuR6JkxOB",
    "outputId": "7631c244-9d8e-4501-e683-cc2bf382c004"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Word      Prob  Similarity\n",
      "138   him  0.004783         0.5\n",
      "2523  dim  0.000090         0.5\n",
      "6666  aim  0.000013         0.5\n",
      "9483  rim  0.000009         0.5\n",
      "9433  imp  0.000004         0.5\n",
      "             Word      Prob  Similarity\n",
      "11890  cultivated  0.000004    0.545455\n",
      "10743   cultivate  0.000004    0.454545\n",
      "10072      motive  0.000013    0.444444\n",
      "14169      mooted  0.000004    0.444444\n",
      "3087      private  0.000058    0.400000\n",
      "                Word      Prob  Similarity\n",
      "11941      graduates  0.000004    0.875000\n",
      "17393    ungraduated  0.000004    0.700000\n",
      "16014        gradual  0.000009    0.625000\n",
      "3844   undergraduate  0.000004    0.583333\n",
      "2370       gradually  0.000045    0.500000\n",
      "                Word      Prob  Similarity\n",
      "15951        partial  0.000004    0.363636\n",
      "9976        venetian  0.000018    0.333333\n",
      "6762            spat  0.000013    0.333333\n",
      "9785   sympathetical  0.000004    0.312500\n",
      "11234      partially  0.000018    0.307692\n",
      "        Word      Prob  Similarity\n",
      "3148    soft  0.000139    0.428571\n",
      "6288   aware  0.000027    0.375000\n",
      "7072  beware  0.000063    0.333333\n",
      "3706  softly  0.000049    0.333333\n",
      "6342  reward  0.000018    0.333333\n",
      "               Word      Prob  Similarity\n",
      "10176   mythologies  0.000009    0.428571\n",
      "13258     analogies  0.000004    0.384615\n",
      "11751   genealogies  0.000009    0.333333\n",
      "13803  phrenologist  0.000009    0.312500\n",
      "7272       colonies  0.000013    0.307692\n",
      "           Word      Prob  Similarity\n",
      "6384    signing  0.000013    0.444444\n",
      "12680  igniting  0.000009    0.400000\n",
      "6939   desiring  0.000004    0.400000\n",
      "10430  reigning  0.000004    0.400000\n",
      "12869  widening  0.000004    0.400000\n",
      "                Word      Prob  Similarity\n",
      "2797       implement  0.000013    0.727273\n",
      "12025     implements  0.000013    0.666667\n",
      "5304      complement  0.000009    0.538462\n",
      "8989       inclement  0.000009    0.461538\n",
      "12405  contemplating  0.000004    0.437500\n",
      "          Word      Prob  Similarity\n",
      "3148      soft  0.000139    0.500000\n",
      "3706    softly  0.000049    0.375000\n",
      "14926   soften  0.000004    0.375000\n",
      "1149       oft  0.000013    0.333333\n",
      "13638  softest  0.000004    0.333333\n",
      "           Word      Prob  Similarity\n",
      "2815   imbedded  0.000009    0.750000\n",
      "12584    bedded  0.000009    0.714286\n",
      "1956     wedded  0.000022    0.500000\n",
      "44     december  0.000022    0.400000\n",
      "5135   redeemed  0.000009    0.400000\n",
      "             Word      Prob  Similarity\n",
      "8237       system  0.000054    0.833333\n",
      "14999       stems  0.000004    0.666667\n",
      "8635         stem  0.000018    0.500000\n",
      "2676   systematic  0.000009    0.500000\n",
      "12271  systemized  0.000004    0.500000\n",
      "             Word      Prob  Similarity\n",
      "4375   developing  0.000004    0.900000\n",
      "13130  enveloping  0.000013    0.583333\n",
      "5088    developed  0.000013    0.500000\n",
      "13653     sloping  0.000013    0.454545\n",
      "9130      popping  0.000004    0.454545\n",
      "           Word      Prob  Similarity\n",
      "56     encoding  0.000004    0.714286\n",
      "16869      ding  0.000027    0.600000\n",
      "16893   bodings  0.000009    0.571429\n",
      "5774   scolding  0.000018    0.500000\n",
      "10081  brooding  0.000009    0.500000\n",
      "             Word      Prob  Similarity\n",
      "4754      resting  0.000054    0.714286\n",
      "9545        sting  0.000009    0.666667\n",
      "9891   protesting  0.000004    0.666667\n",
      "1511  interesting  0.000036    0.600000\n",
      "6316       stingy  0.000004    0.571429\n",
      "           Word      Prob  Similarity\n",
      "3670    hugging  0.000009    0.444444\n",
      "16862   tugging  0.000004    0.444444\n",
      "14664  drugging  0.000004    0.400000\n",
      "13083     ingin  0.000004    0.375000\n",
      "3603     giving  0.000126    0.333333\n",
      "             Word      Prob  Similarity\n",
      "8693    political  0.000009    0.545455\n",
      "13623  analogical  0.000004    0.500000\n",
      "7479     critical  0.000067    0.454545\n",
      "9127     nautical  0.000018    0.454545\n",
      "11022    analytic  0.000004    0.454545\n",
      "          Word      Prob  Similarity\n",
      "880      skill  0.000045    0.600000\n",
      "230      kills  0.000013    0.600000\n",
      "14271  skilful  0.000009    0.428571\n",
      "16819  huskily  0.000004    0.428571\n",
      "3098      skin  0.000166    0.400000\n",
      " him a highly cultivated graduates about partial making new soft engineering mythologies signing and implement soft of imbedded devices and system also developing encoding resting and hugging political skill\n"
     ]
    }
   ],
   "source": [
    "print(autocorrect(\"Im a highly motivated graduate,about spatialNET making new software engineering tecnologies,desgning and implementing softwre of embedded devices and systems,also developping,coding,testing and debuging analitical skils\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "testing",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
